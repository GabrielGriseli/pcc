% REFERENCIAL TEORICO----------------------------------------------------------

\chapter{REFERÊNCIAL TEÓRICO}
\label{chap:ref-teorico}

% \section{Computação de Alto Desempenho}
\section{Programação Paralela}

Um programa de processamento paralelo é um único programa que é executado em vários processadores simultaneamente.
A programação paralela pode ser usada para o reduzir o tempo de execução de um programa,
que busca encontrar uma solução para um problema complexo, como por exemplo, problemas voltados as áreas científicas \cite{hennessy2014organizaccao}.

A diferença de um programa sequencial para um programa paralelo, é que um programa sequencial é visto como uma série de instruções
sequenciais que devem ser executadas em um único processador.
Já um programa paralelo, é visto como um conjunto de partes que podem ser resolvidos concorrentemente,
essas partes, são constituídas de instruções sequenciais \cite{hennessy2014organizaccao,tanenbaum20103a}
% \subsection{Classificação e Terminologia}

\section{Arquiteturas Voltadas a Computação Heterogênea}
Muitas das arquiteturas que estão atualmente nos supercomputadores é voltada a computação heterogênea \cite{meuer2014top500}.
O termo heterogênea, descreve que diferentes arquiteturas possam ser usadas em um mesmo nó computacional, como por exemplo, processadores multicore e aceleradores como a GPU e a FPGAs \cite{intrArqHete:2012}.

\subsection{Processadores \textit{Multicore}}
Os processadores \textit{multicore} ou de múltiplos núcleos, são um único componente de computação (um único chip), com duas ou mais unidade de processamento que são chamadas de núcleos. \cite{blake2009survey}
“logo um microprocessador quadcore é um chip que contém quatro processadores, ou quatro núcleos” \cite[p.~31]{hennessy2014organizaccao}

Os multiprocessadores com múltiplos núcleos ganharam destaque nos últimos anos, “a partir de 2006 todas as empresas de desktop e servidor estavam usando microprocessadores com múltiplos processadores por chip” \cite[p.~31]{hennessy2014organizaccao}
O motivo de se tornarem tão populares foi a barreira física encontra no aumento de desempenho dos processadores sequenciais, que era baseado no aumento da frequência de \textit{clock} \cite{hennessy2014organizaccao}.

Para o sistema operacional cada núcleo é visto como um processador lógico independente.

\begin{citacao}
Cada CPU tem sua própria memória e sua própria cópia privada do sistema operacional.
Em consequência, as \emph{n} CPUs operam então como \emph{n} computadores independentes.
Uma otimização obvia consiste em permitir que todas as CPUs compartilhem o código do sistema operacional e façam cópias privadas somente dos dados. \cite[p.~331]{tanenbaum20103a}
\end{citacao}

Para programar processadores \textit{multicore} pode-se optar por utilizar ferramentas como OpenMP e Intel TBB.
OpenMP é uma API que suporta programação de processadores \textit{multicore} em C/C++ e Fortran.
A API consiste na adição de diretivas de compilação para indicar blocos que podem paralelizados.
Intel TBB é uma biblioteca desenvolvida pela Intel, onde são usados \textit{templates} para programação paralela em linguagem C++,
neste caso não são necessários a utilização de linguagens ou compiladores especiais

\subsection{Aceleradores}
Um acelerador é um \textit{hardware} que tem a função de executar algumas instruções mais eficientes,
quando comparada com a CPU. São exemplos de aceleradores as GPUs e as FPGAs \cite{kindratenko2010high}.

\subsubsection{GPUs}
As GPUs, em português, unidade de processamento gráfico, inicialmente foram desenvolvidas para ser um processador otimizado para gráficos 2D e 3D, vídeo,
computação visual e exibição de dados.
As GPUs modernas são um multiprocessador altamente paralelo e \textit{multithread}, que podem ser utilizadas para resolver problemas complexos com programas paralelos \cite{hennessy2014organizaccao}.
No contexto das arquiteturas heterogêneas podemos encontrar as GPUs trabalhando com as CPUs em nosso dia a dia, como por exemplo.
“PCs e consoles de jogo combinam uma GPU com uma CPU para formar sistemas heterogêneos” \cite[p.~A-569]{hennessy2014organizaccao}.

Para ser possível programar aplicações de computação paralela em GPUs, opta-se geralmente por modelos de programação, como CUDA e OpenCL.
CUDA, é uma interface para programação paralela escalável baseada em linguagem C/C++, para GPUs fabricadas pela NVIDIA \cite{hennessy2014organizaccao}.

OpenCL, é uma interface voltada para programação paralela em ambientes heterogêneos, possibilitando que o desenvolvimento da aplicação seja executado em diferentes dispositivos instalados em uma máquina (CPU-GPU).
Diferente da interface CUDA, a OpenCL não está vinculada a uma fabricante de GPU, portanto o desenvolvimento de aplicações com essa interface não fica limitado a um fabricante específico \cite{opencl:2018}.

\section{Ambientes de Execução para Arquiteturas Heterogêneas}
\subsection{StarPU}
\subsection{Xkaapi}
\subsection{StarSs}

\section{Paradigma de Grafo de Dependência de Tarefas}

\section{Transferência de Calor em Placas Metálicas}